{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":127736,"sourceType":"datasetVersion","datasetId":64890}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ğŸ¬ MovieBot\nAsk me anything about movie plots!\n# RAG application to answer movie plots by their name.\n\n## Features:\n- Uses `LangGraph` to structure the app\n- Uses wikipedia-movie-plotsdataset for RAG using chroma\n- Simple chat interface\n\n**Type 'exit' to quit the chat.**","metadata":{}},{"cell_type":"markdown","source":"Setup\nFirst, install ChromaDB and the Gemini API Python SDK.","metadata":{}},{"cell_type":"code","source":"\n!pip uninstall -qqy jupyterlab kfp  # Remove unused conflicting packages\n!pip install -qU \"google-genai==1.7.0\" \"chromadb==0.6.3\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T03:35:11.082535Z","iopub.execute_input":"2025-04-07T03:35:11.083031Z","iopub.status.idle":"2025-04-07T03:35:59.070203Z","shell.execute_reply.started":"2025-04-07T03:35:11.082998Z","shell.execute_reply":"2025-04-07T03:35:59.068809Z"}},"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Skipping kfp as it is not installed.\u001b[0m\u001b[33m\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m144.7/144.7 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m611.1/611.1 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m100.9/100.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m99.2/99.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m183.4/183.4 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m65.2/65.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m442.1/442.1 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m452.9/452.9 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngoogle-api-core 1.34.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5, but you have protobuf 5.29.4 which is incompatible.\ngoogle-cloud-bigtable 2.27.0 requires google-api-core[grpc]<3.0.0dev,>=2.16.0, but you have google-api-core 1.34.1 which is incompatible.\ngoogle-cloud-translate 3.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.29.4 which is incompatible.\npandas-gbq 0.25.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\ntensorflow 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.4 which is incompatible.\ntensorflow-decision-forests 1.10.0 requires tensorflow==2.17.0, but you have tensorflow 2.17.1 which is incompatible.\ntensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 5.29.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"pip install pandas","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T03:35:59.072029Z","iopub.execute_input":"2025-04-07T03:35:59.072501Z","iopub.status.idle":"2025-04-07T03:36:03.959967Z","shell.execute_reply.started":"2025-04-07T03:35:59.072449Z","shell.execute_reply":"2025-04-07T03:36:03.958343Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.3)\nRequirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.22.4->pandas) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.22.4->pandas) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.22.4->pandas) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.22.4->pandas) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.22.4->pandas) (2024.2.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from google import genai\nfrom google.genai import types\n\nfrom IPython.display import Markdown\n\ngenai.__version__","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T03:36:03.962161Z","iopub.execute_input":"2025-04-07T03:36:03.962494Z","iopub.status.idle":"2025-04-07T03:36:05.621233Z","shell.execute_reply.started":"2025-04-07T03:36:03.962465Z","shell.execute_reply":"2025-04-07T03:36:05.620101Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"'1.7.0'"},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"Set up AI key stored in Kaggle secret names GOOGLE_API_KEY.To make the key available through Kaggle secrets, choose Secrets from the Add-ons menu and follow the instructions to add your key or enable it for this notebook.","metadata":{}},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\n\nGOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T03:36:05.622938Z","iopub.execute_input":"2025-04-07T03:36:05.623650Z","iopub.status.idle":"2025-04-07T03:36:05.797388Z","shell.execute_reply.started":"2025-04-07T03:36:05.623577Z","shell.execute_reply":"2025-04-07T03:36:05.796215Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"client = genai.Client(api_key=GOOGLE_API_KEY)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T03:36:05.798454Z","iopub.execute_input":"2025-04-07T03:36:05.798894Z","iopub.status.idle":"2025-04-07T03:36:06.201891Z","shell.execute_reply.started":"2025-04-07T03:36:05.798860Z","shell.execute_reply":"2025-04-07T03:36:06.200579Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"Read CSV using pandas and for each row store 'Title' and 'plot' in docs.\nGenerates list of documents(docs), each containing the title and plot of the movie.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\ndf = pd.read_csv(\"/kaggle/input/wikipedia-movie-plots/wiki_movie_plots_deduped.csv\")\n#df_filtered = df[(df['Release Year'] >= 2000) & (df['Release Year'] < 2026) & (df['Genre'].str.contains('action', case=False, na=False))]\ndocs = [\n    f\"Title: {row['Title']}\\nPlot: {row['Plot']}\"\n    for _, row in df.iterrows()\n]\n#df_filtered.count()\ndf.count()\nlen(docs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T03:36:06.203931Z","iopub.execute_input":"2025-04-07T03:36:06.204481Z","iopub.status.idle":"2025-04-07T03:36:10.744697Z","shell.execute_reply.started":"2025-04-07T03:36:06.204433Z","shell.execute_reply":"2025-04-07T03:36:10.743485Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"34886"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"Creating an embedding database using ChromaDB involves generating document embeddings with the Gemini API using the retrieval_document task type. These embeddings support a retrieval system where query embeddings (retrieval_query) are used later for matching.","metadata":{}},{"cell_type":"code","source":"from chromadb import Documents, EmbeddingFunction, Embeddings\nfrom google.api_core import retry\n\nfrom google.genai import types\nis_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503})\nclass GeminiEmbeddingFunction(EmbeddingFunction):\n    # Specify whether to generate embeddings for documents, or queries\n    document_mode = True\n\n    @retry.Retry(predicate=is_retriable)\n    def __call__(self, input: Documents) -> Embeddings:\n        if self.document_mode:\n            embedding_task = \"retrieval_document\"\n        else:\n            embedding_task = \"retrieval_query\"\n\n        response = client.models.embed_content(\n            model=\"models/text-embedding-004\",\n            contents=input,\n            config=types.EmbedContentConfig(\n                task_type=embedding_task,\n            ),\n        )\n        return [e.values for e in response.embeddings]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T03:36:10.746067Z","iopub.execute_input":"2025-04-07T03:36:10.746450Z","iopub.status.idle":"2025-04-07T03:36:11.798931Z","shell.execute_reply.started":"2025-04-07T03:36:10.746411Z","shell.execute_reply":"2025-04-07T03:36:11.797651Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"### Creating and Populating a ChromaDB Collection with Gemini Embeddings\n\nThis code initializes a ChromaDB collection using a custom `GeminiEmbeddingFunction` for document embeddings.  \nIt processes documents in batches and adds them to the database with unique IDs.  \nErrors during embedding or addition are handled with specific messages for debugging.  \nThe batching ensures memory efficiency and prevents API overload, completing with a confirmation message.  \n(Takes 349 batches for this data)","metadata":{}},{"cell_type":"code","source":"import chromadb\n\nDB_NAME = \"googlecardb\"\n\nembed_fn = GeminiEmbeddingFunction()\nembed_fn.document_mode = True\n\nchroma_client = chromadb.Client()\ndb = chroma_client.get_or_create_collection(name=DB_NAME, embedding_function=embed_fn)\n\n#db.add(documents=docs, ids=[str(i) for i in range(len(docs))])\ndef embed_batch(batch_docs):\n    \"\"\"Embeds a batch of documents using your embedding function.\"\"\"\n    return embed_fn(input=batch_docs)\n\nbatch_size = 100  # Adjust this value\nnum_docs = len(docs)\n\nfor i in range(0, num_docs, batch_size):\n    batch_docs = docs[i : i + batch_size]\n    batch_ids = [str(j) for j in range(i, i + len(batch_docs))]\n\n    if batch_docs:\n        try:\n            db.add(documents=batch_docs, ids=batch_ids)\n            print(f\"Added batch {i // batch_size + 1} of size {len(batch_docs)}\")\n        except genai_errors.ClientError as e:\n            print(f\"Google AI ClientError in batch {i // batch_size + 1}:\")\n            print(f\"  Status Code: {e.status_code}\")\n            print(f\"  Error Message: {e.message}\")\n            # You might want to implement more specific handling here,\n            # like reducing the batch size further or logging the error.\n        except Exception as e:\n            print(f\"An unexpected error occurred in batch {i // batch_size + 1}: {e}\")\n            # Handle other potential exceptions\n# ... rest of your code ...\n\nprint(\"Finished adding all documents in batches.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T03:36:11.800173Z","iopub.execute_input":"2025-04-07T03:36:11.800885Z","iopub.status.idle":"2025-04-07T03:42:56.330013Z","shell.execute_reply.started":"2025-04-07T03:36:11.800854Z","shell.execute_reply":"2025-04-07T03:42:56.328871Z"}},"outputs":[{"name":"stdout","text":"Added batch 1 of size 100\nAdded batch 2 of size 100\nAdded batch 3 of size 100\nAdded batch 4 of size 100\nAdded batch 5 of size 100\nAdded batch 6 of size 100\nAdded batch 7 of size 100\nAdded batch 8 of size 100\nAdded batch 9 of size 100\nAdded batch 10 of size 100\nAdded batch 11 of size 100\nAdded batch 12 of size 100\nAdded batch 13 of size 100\nAdded batch 14 of size 100\nAdded batch 15 of size 100\nAdded batch 16 of size 100\nAdded batch 17 of size 100\nAdded batch 18 of size 100\nAdded batch 19 of size 100\nAdded batch 20 of size 100\nAdded batch 21 of size 100\nAdded batch 22 of size 100\nAdded batch 23 of size 100\nAdded batch 24 of size 100\nAdded batch 25 of size 100\nAdded batch 26 of size 100\nAdded batch 27 of size 100\nAdded batch 28 of size 100\nAdded batch 29 of size 100\nAdded batch 30 of size 100\nAdded batch 31 of size 100\nAdded batch 32 of size 100\nAdded batch 33 of size 100\nAdded batch 34 of size 100\nAdded batch 35 of size 100\nAdded batch 36 of size 100\nAdded batch 37 of size 100\nAdded batch 38 of size 100\nAdded batch 39 of size 100\nAdded batch 40 of size 100\nAdded batch 41 of size 100\nAdded batch 42 of size 100\nAdded batch 43 of size 100\nAdded batch 44 of size 100\nAdded batch 45 of size 100\nAdded batch 46 of size 100\nAdded batch 47 of size 100\nAdded batch 48 of size 100\nAdded batch 49 of size 100\nAdded batch 50 of size 100\nAdded batch 51 of size 100\nAdded batch 52 of size 100\nAdded batch 53 of size 100\nAdded batch 54 of size 100\nAdded batch 55 of size 100\nAdded batch 56 of size 100\nAdded batch 57 of size 100\nAdded batch 58 of size 100\nAdded batch 59 of size 100\nAdded batch 60 of size 100\nAdded batch 61 of size 100\nAdded batch 62 of size 100\nAdded batch 63 of size 100\nAdded batch 64 of size 100\nAdded batch 65 of size 100\nAdded batch 66 of size 100\nAdded batch 67 of size 100\nAdded batch 68 of size 100\nAdded batch 69 of size 100\nAdded batch 70 of size 100\nAdded batch 71 of size 100\nAdded batch 72 of size 100\nAdded batch 73 of size 100\nAdded batch 74 of size 100\nAdded batch 75 of size 100\nAdded batch 76 of size 100\nAdded batch 77 of size 100\nAdded batch 78 of size 100\nAdded batch 79 of size 100\nAdded batch 80 of size 100\nAdded batch 81 of size 100\nAdded batch 82 of size 100\nAdded batch 83 of size 100\nAdded batch 84 of size 100\nAdded batch 85 of size 100\nAdded batch 86 of size 100\nAdded batch 87 of size 100\nAdded batch 88 of size 100\nAdded batch 89 of size 100\nAdded batch 90 of size 100\nAdded batch 91 of size 100\nAdded batch 92 of size 100\nAdded batch 93 of size 100\nAdded batch 94 of size 100\nAdded batch 95 of size 100\nAdded batch 96 of size 100\nAdded batch 97 of size 100\nAdded batch 98 of size 100\nAdded batch 99 of size 100\nAdded batch 100 of size 100\nAdded batch 101 of size 100\nAdded batch 102 of size 100\nAdded batch 103 of size 100\nAdded batch 104 of size 100\nAdded batch 105 of size 100\nAdded batch 106 of size 100\nAdded batch 107 of size 100\nAdded batch 108 of size 100\nAdded batch 109 of size 100\nAdded batch 110 of size 100\nAdded batch 111 of size 100\nAdded batch 112 of size 100\nAdded batch 113 of size 100\nAdded batch 114 of size 100\nAdded batch 115 of size 100\nAdded batch 116 of size 100\nAdded batch 117 of size 100\nAdded batch 118 of size 100\nAdded batch 119 of size 100\nAdded batch 120 of size 100\nAdded batch 121 of size 100\nAdded batch 122 of size 100\nAdded batch 123 of size 100\nAdded batch 124 of size 100\nAdded batch 125 of size 100\nAdded batch 126 of size 100\nAdded batch 127 of size 100\nAdded batch 128 of size 100\nAdded batch 129 of size 100\nAdded batch 130 of size 100\nAdded batch 131 of size 100\nAdded batch 132 of size 100\nAdded batch 133 of size 100\nAdded batch 134 of size 100\nAdded batch 135 of size 100\nAdded batch 136 of size 100\nAdded batch 137 of size 100\nAdded batch 138 of size 100\nAdded batch 139 of size 100\nAdded batch 140 of size 100\nAdded batch 141 of size 100\nAdded batch 142 of size 100\nAdded batch 143 of size 100\nAdded batch 144 of size 100\nAdded batch 145 of size 100\nAdded batch 146 of size 100\nAdded batch 147 of size 100\nAdded batch 148 of size 100\nAdded batch 149 of size 100\nAdded batch 150 of size 100\nAdded batch 151 of size 100\nAdded batch 152 of size 100\nAdded batch 153 of size 100\nAdded batch 154 of size 100\nAdded batch 155 of size 100\nAdded batch 156 of size 100\nAdded batch 157 of size 100\nAdded batch 158 of size 100\nAdded batch 159 of size 100\nAdded batch 160 of size 100\nAdded batch 161 of size 100\nAdded batch 162 of size 100\nAdded batch 163 of size 100\nAdded batch 164 of size 100\nAdded batch 165 of size 100\nAdded batch 166 of size 100\nAdded batch 167 of size 100\nAdded batch 168 of size 100\nAdded batch 169 of size 100\nAdded batch 170 of size 100\nAdded batch 171 of size 100\nAdded batch 172 of size 100\nAdded batch 173 of size 100\nAdded batch 174 of size 100\nAdded batch 175 of size 100\nAdded batch 176 of size 100\nAdded batch 177 of size 100\nAdded batch 178 of size 100\nAdded batch 179 of size 100\nAdded batch 180 of size 100\nAdded batch 181 of size 100\nAdded batch 182 of size 100\nAdded batch 183 of size 100\nAdded batch 184 of size 100\nAdded batch 185 of size 100\nAdded batch 186 of size 100\nAdded batch 187 of size 100\nAdded batch 188 of size 100\nAdded batch 189 of size 100\nAdded batch 190 of size 100\nAdded batch 191 of size 100\nAdded batch 192 of size 100\nAdded batch 193 of size 100\nAdded batch 194 of size 100\nAdded batch 195 of size 100\nAdded batch 196 of size 100\nAdded batch 197 of size 100\nAdded batch 198 of size 100\nAdded batch 199 of size 100\nAdded batch 200 of size 100\nAdded batch 201 of size 100\nAdded batch 202 of size 100\nAdded batch 203 of size 100\nAdded batch 204 of size 100\nAdded batch 205 of size 100\nAdded batch 206 of size 100\nAdded batch 207 of size 100\nAdded batch 208 of size 100\nAdded batch 209 of size 100\nAdded batch 210 of size 100\nAdded batch 211 of size 100\nAdded batch 212 of size 100\nAdded batch 213 of size 100\nAdded batch 214 of size 100\nAdded batch 215 of size 100\nAdded batch 216 of size 100\nAdded batch 217 of size 100\nAdded batch 218 of size 100\nAdded batch 219 of size 100\nAdded batch 220 of size 100\nAdded batch 221 of size 100\nAdded batch 222 of size 100\nAdded batch 223 of size 100\nAdded batch 224 of size 100\nAdded batch 225 of size 100\nAdded batch 226 of size 100\nAdded batch 227 of size 100\nAdded batch 228 of size 100\nAdded batch 229 of size 100\nAdded batch 230 of size 100\nAdded batch 231 of size 100\nAdded batch 232 of size 100\nAdded batch 233 of size 100\nAdded batch 234 of size 100\nAdded batch 235 of size 100\nAdded batch 236 of size 100\nAdded batch 237 of size 100\nAdded batch 238 of size 100\nAdded batch 239 of size 100\nAdded batch 240 of size 100\nAdded batch 241 of size 100\nAdded batch 242 of size 100\nAdded batch 243 of size 100\nAdded batch 244 of size 100\nAdded batch 245 of size 100\nAdded batch 246 of size 100\nAdded batch 247 of size 100\nAdded batch 248 of size 100\nAdded batch 249 of size 100\nAdded batch 250 of size 100\nAdded batch 251 of size 100\nAdded batch 252 of size 100\nAdded batch 253 of size 100\nAdded batch 254 of size 100\nAdded batch 255 of size 100\nAdded batch 256 of size 100\nAdded batch 257 of size 100\nAdded batch 258 of size 100\nAdded batch 259 of size 100\nAdded batch 260 of size 100\nAdded batch 261 of size 100\nAdded batch 262 of size 100\nAdded batch 263 of size 100\nAdded batch 264 of size 100\nAdded batch 265 of size 100\nAdded batch 266 of size 100\nAdded batch 267 of size 100\nAdded batch 268 of size 100\nAdded batch 269 of size 100\nAdded batch 270 of size 100\nAdded batch 271 of size 100\nAdded batch 272 of size 100\nAdded batch 273 of size 100\nAdded batch 274 of size 100\nAdded batch 275 of size 100\nAdded batch 276 of size 100\nAdded batch 277 of size 100\nAdded batch 278 of size 100\nAdded batch 279 of size 100\nAdded batch 280 of size 100\nAdded batch 281 of size 100\nAdded batch 282 of size 100\nAdded batch 283 of size 100\nAdded batch 284 of size 100\nAdded batch 285 of size 100\nAdded batch 286 of size 100\nAdded batch 287 of size 100\nAdded batch 288 of size 100\nAdded batch 289 of size 100\nAdded batch 290 of size 100\nAdded batch 291 of size 100\nAdded batch 292 of size 100\nAdded batch 293 of size 100\nAdded batch 294 of size 100\nAdded batch 295 of size 100\nAdded batch 296 of size 100\nAdded batch 297 of size 100\nAdded batch 298 of size 100\nAdded batch 299 of size 100\nAdded batch 300 of size 100\nAdded batch 301 of size 100\nAdded batch 302 of size 100\nAdded batch 303 of size 100\nAdded batch 304 of size 100\nAdded batch 305 of size 100\nAdded batch 306 of size 100\nAdded batch 307 of size 100\nAdded batch 308 of size 100\nAdded batch 309 of size 100\nAdded batch 310 of size 100\nAdded batch 311 of size 100\nAdded batch 312 of size 100\nAdded batch 313 of size 100\nAdded batch 314 of size 100\nAdded batch 315 of size 100\nAdded batch 316 of size 100\nAdded batch 317 of size 100\nAdded batch 318 of size 100\nAdded batch 319 of size 100\nAdded batch 320 of size 100\nAdded batch 321 of size 100\nAdded batch 322 of size 100\nAdded batch 323 of size 100\nAdded batch 324 of size 100\nAdded batch 325 of size 100\nAdded batch 326 of size 100\nAdded batch 327 of size 100\nAdded batch 328 of size 100\nAdded batch 329 of size 100\nAdded batch 330 of size 100\nAdded batch 331 of size 100\nAdded batch 332 of size 100\nAdded batch 333 of size 100\nAdded batch 334 of size 100\nAdded batch 335 of size 100\nAdded batch 336 of size 100\nAdded batch 337 of size 100\nAdded batch 338 of size 100\nAdded batch 339 of size 100\nAdded batch 340 of size 100\nAdded batch 341 of size 100\nAdded batch 342 of size 100\nAdded batch 343 of size 100\nAdded batch 344 of size 100\nAdded batch 345 of size 100\nAdded batch 346 of size 100\nAdded batch 347 of size 100\nAdded batch 348 of size 100\nAdded batch 349 of size 86\nFinished adding all documents in batches.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"db.count()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T03:42:56.332487Z","iopub.execute_input":"2025-04-07T03:42:56.332834Z","iopub.status.idle":"2025-04-07T03:42:56.346721Z","shell.execute_reply.started":"2025-04-07T03:42:56.332805Z","shell.execute_reply":"2025-04-07T03:42:56.345605Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"34886"},"metadata":{}}],"execution_count":9},{"cell_type":"markdown","source":"Retrieval: Find relevant documents\nTo search the Chroma database, call the query method. Switch to the retrieval_query mode of embedding generation.","metadata":{}},{"cell_type":"code","source":"# Switch to query mode when generating embeddings.\nembed_fn.document_mode = False\n\n# Search the Chroma DB using the specified query.\nquery = \"which is the scariest movie?\"\n\nresult = db.query(query_texts=[query], n_results=1)\n[all_passages] = result[\"documents\"]\n\nMarkdown(all_passages[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T03:42:56.348581Z","iopub.execute_input":"2025-04-07T03:42:56.348972Z","iopub.status.idle":"2025-04-07T03:42:56.544038Z","shell.execute_reply.started":"2025-04-07T03:42:56.348942Z","shell.execute_reply":"2025-04-07T03:42:56.543027Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Title: Clownhouse\nPlot: The story follows Casey, a normal boy whose life is constantly influenced by his intense fear of clowns. His two older brothers, Geoffrey and Randy, are mostly disobliging. One night, the three boys are left alone when their mother visits relatives, so they decide to visit a local circus for a night of amusement, despite Casey's uncontrollable coulrophobia. Meanwhile, the local state insane asylum has sent a majority of the hospital's inmates to the carnival for therapy, but three psychotic mental patients break away from the group and kill three clowns, taking their makeup and costumes.\r\nWhile at the circus, Casey innocently visits a fortune teller despite Randy's better judgment. The fortune teller reveals to Casey that his life line has been cut short, and says to him: \"Beware, beware, in the darkest of dark /though the flesh is young and the hearts are strong /precious life cannot be long /when darkest death has left its mark.\"\r\nAs the boys return from the circus, a shaken Casey thinks his nightmare is over, but it has only just begun. When the clowns target their home, Casey is forced to face his fears once and for all. Casey and his brothers are locked inside their isolated farmhouse and the power is turned off. Casey attempts to call the police, but because Casey says that the \"clowns from the circus are trying to get him\", the police officers assume that Casey's fear of clowns caused him to have a realistic nightmare. The officers tell Casey that everything will be fine if he goes back to sleep, and hangs up.\r\nRandy mockingly dresses up as a clown, disbelieving of Casey's claims that clowns are inside the house. His plan to jump out at Geoffrey and Casey is cut short after he is stabbed by one of the clowns. Geoffrey manages to kill the first clown by hitting him with a wooden plank, knocking him down a flight of stairs and breaking his neck.\r\nLater on, after tricking the clown, Casey and Geoffrey push another clown out a window to his death. Casey and Geoffrey find Randy unconscious in a closet and drag him into another room. Geoffrey is then attacked and presumably killed by the final clown, who chases Casey into the upstairs game room. Casey manages to hide for the time being, but after the clown leaves, Casey accidentally steps on a noise-making toy, alerting the clown of his presence. The enraged clown attempts to break Casey's neck, but he is then killed by Geoffrey (who survived the clown's attack), slamming a hatchet into the killer's back, and the two exhausted and traumatized brothers hug each other as the police finally arrive to help them.\r\nThe film ends with this narration:"},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"### Constructing a Prompt for Gemini Query Response\n\nThis code prepares a custom prompt for Gemini by first formatting the user query into a single line.  \nIt defines the assistant's tone and instructions for how to answer, encouraging complete, friendly, and relevant responses.Each retrieved document passage is cleaned and appended to the prompt as context.  \nThe final prompt is printed, ready to be used for generating a contextual response from the model.  \n","metadata":{}},{"cell_type":"code","source":"query_oneline = query.replace(\"\\n\", \" \")\n\n# This prompt is where you can specify any guidance on tone, or what topics the model should stick to, or avoid.\nprompt = f\"\"\"You are a helpful and informative bot that answers questions using text from the reference passage included below. \nBe sure to respond in a complete sentence, being comprehensive, including all relevant background information. \nstrike a friendly and converstional tone. If the passage is irrelevant to the answer, you may ignore it.\n\nQUESTION: {query_oneline}\n\"\"\"\n\n# Add the retrieved documents to the prompt.\nfor passage in all_passages:\n    passage_oneline = passage.replace(\"\\n\", \" \")\n    prompt += f\"PASSAGE: {passage_oneline}\\n\"\n\nprint(prompt)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T03:42:56.545197Z","iopub.execute_input":"2025-04-07T03:42:56.545580Z","iopub.status.idle":"2025-04-07T03:42:56.551870Z","shell.execute_reply.started":"2025-04-07T03:42:56.545546Z","shell.execute_reply":"2025-04-07T03:42:56.550883Z"}},"outputs":[{"name":"stdout","text":"You are a helpful and informative bot that answers questions using text from the reference passage included below. \nBe sure to respond in a complete sentence, being comprehensive, including all relevant background information. \nstrike a friendly and converstional tone. If the passage is irrelevant to the answer, you may ignore it.\n\nQUESTION: which is the scariest movie?\n The film ends with this narration:, Casey and Geoffrey push another clown out a window to his death. Casey and Geoffrey find Randy unconscious in a closet and drag him into another room. Geoffrey is then attacked and presumably killed by the final clown, who chases Casey into the upstairs game room. Casey manages to hide for the time being, but after the clown leaves, Casey accidentally steps on a noise-making toy, alerting the clown of his presence. The enraged clown attempts to break Casey's neck, but he is then killed by Geoffrey (who survived the clown's attack), slamming a hatchet into the killer's back, and the two exhausted and traumatized brothers hug each other as the police finally arrive to help them.\n\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"use the generate_content method to to generate an answer to the question.","metadata":{}},{"cell_type":"code","source":"answer = client.models.generate_content(\n    model=\"gemini-2.0-flash\",\n    contents=prompt)\n\nMarkdown(answer.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T03:42:56.552914Z","iopub.execute_input":"2025-04-07T03:42:56.553207Z","iopub.status.idle":"2025-04-07T03:42:57.193394Z","shell.execute_reply.started":"2025-04-07T03:42:56.553170Z","shell.execute_reply":"2025-04-07T03:42:57.192462Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Well, according to the passage, the movie \"Clownhouse\" follows a boy named Casey, who is constantly influenced by his fear of clowns, and he is forced to face his fears when the clowns target his home.\n"},"metadata":{}}],"execution_count":12},{"cell_type":"markdown","source":"Add everything in the function.","metadata":{}},{"cell_type":"code","source":"def get_answer(query: str) -> str:\n\n    embed_fn.document_mode = False\n    result = db.query(query_texts=[query], n_results=1)\n    if result and result[\"documents\"] and result[\"documents\"][0]:\n        [all_passages] = result[\"documents\"]\n        query_oneline = query.replace(\"\\n\", \" \")\n\n        prompt = f\"\"\"You are a helpful and informative bot that answers questions using text from the reference passage included below.\n        Be sure to respond in a complete sentence, being comprehensive, including all relevant background information.\n        strike a friendly and converstional tone. If the passage is irrelevant to the answer, you may ignore it.\n\n        QUESTION: {query_oneline}\n        \"\"\"\n\n        for passage in all_passages:\n            passage_oneline = passage.replace(\"\\n\", \" \")\n            prompt += f\"PASSAGE: {passage_oneline}\\n\"\n\n        response = client.models.generate_content(\n            model=\"gemini-2.0-flash\",\n            contents=prompt\n        )\n        return response.text\n    else:\n        return \"No relevant information found in the database.\"\n\n\n# 1. Define your query:\nyour_query = \"which is the scariest movie?\"\n\n# 2. Call the get_answer function:\nanswer_text = get_answer(your_query)\n\n# 3. Print the answer in Markdown format:\nprint(\"```markdown\")\nprint(answer_text)\nprint(\"```\")\n\n# --- Example with another query ---\nanother_query = \"What is the plot of a famous action movie?\"\nanother_answer = get_answer(another_query)\nprint(\"\\n```markdown\")\nprint(another_answer)\nprint(\"```\")\n    \n\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T03:42:57.194407Z","iopub.execute_input":"2025-04-07T03:42:57.194786Z","iopub.status.idle":"2025-04-07T03:42:59.143786Z","shell.execute_reply.started":"2025-04-07T03:42:57.194758Z","shell.execute_reply":"2025-04-07T03:42:59.142753Z"}},"outputs":[{"name":"stdout","text":"```markdown\nWell, based on the passage, the movie \"Clownhouse\" tells the story of Casey, a boy with an intense fear of clowns, who must face his fears when psychotic mental patients dressed as clowns target his home, so if you are looking for a scary movie featuring clowns, this could be a good choice for you!\n\n```\n\n```markdown\nThe movie Commando follows retired United States Special Forces Colonel John Matrix, whose daughter is kidnapped by mercenaries led by a former dictator named Arius. Arius blackmails Matrix into carrying out a political assassination in Val Verde, but Matrix escapes and, with the help of a flight attendant named Cindy, sets out to rescue his daughter, Jenny, leading to a climactic showdown at Arius's island hideout where Matrix defeats the villains and saves his daughter.\n\n```\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"Install dependencies for Langgraph.","metadata":{}},{"cell_type":"code","source":"!pip uninstall -qqy kfp jupyterlab libpysal thinc spacy fastai ydata-profiling google-cloud-bigquery google-generativeai\n!pip install -qU 'langgraph==0.3.21' 'langgraph-prebuilt==0.1.7'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T03:42:59.144732Z","iopub.execute_input":"2025-04-07T03:42:59.145109Z","iopub.status.idle":"2025-04-07T03:43:10.786663Z","shell.execute_reply.started":"2025-04-07T03:42:59.145081Z","shell.execute_reply":"2025-04-07T03:43:10.785301Z"}},"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Skipping kfp as it is not installed.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Skipping jupyterlab as it is not installed.\u001b[0m\u001b[33m\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m138.0/138.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m223.6/223.6 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"### `rag_qa_node` â€“ Handling RAG-Based Question Answering\n\nThis function defines a node in a Retrieval-Augmented Generation (RAG) pipeline.  \nIt extracts the latest user query from the chat state and passes it to a `get_answer()` function to retrieve an appropriate response.  \nThe assistantâ€™s answer is appended to the conversation history.  \nThe updated state is then returned to continue the dialogue flow.\n","metadata":{}},{"cell_type":"code","source":"def rag_qa_node(state):\n    query = state[\"messages\"][-1][\"content\"]\n    answer = get_answer(query)  # Your existing function\n    state[\"messages\"].append({\"role\": \"assistant\", \"content\": answer})\n    return state","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T03:43:10.788170Z","iopub.execute_input":"2025-04-07T03:43:10.788692Z","iopub.status.idle":"2025-04-07T03:43:10.794531Z","shell.execute_reply.started":"2025-04-07T03:43:10.788646Z","shell.execute_reply":"2025-04-07T03:43:10.793513Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"### Using LangGraph\n\nCreates a simple movie-focused chatbot using `LangGraph`. Here's what each part does:\n\n1. **Chat State Definition**  \n   A `ChatState` Pydantic model is defined to maintain the list of messages exchanged during the chat.\n\n2. **RAG QA Node Logic**  \n   The `rag_qa_node` checks if the user's query is movie-related and retrieves an answer using `get_answer()`. If no meaningful response is found, it uses a fallback message.\n\n3. **LangGraph Flow**  \n   A `StateGraph` is constructed using LangGraph. The `rag_qa_node` is registered as the sole node, serving both as the entry and end point. The app is compiled to handle chat execution.\n\n4. **Running the Chatbot**  \n   The `start_chat()` function starts an interactive session, where user queries are sent to the LangGraph-powered assistant. It continues until the user types `exit` or `quit`.\n","metadata":{}},{"cell_type":"code","source":"from langgraph.graph import StateGraph, END\nfrom pydantic import BaseModel\nfrom typing import List, Dict\nfrom IPython.display import Image, display\n\n\n# Define the ChatState model\nclass ChatState(BaseModel):\n    messages: List[Dict[str, str]]\n\n# Fallback function for unanswered questions\ndef fallback():\n    return \"Sorry, My knowledge is limited to movie plots only. Could you ask something else?\"\n\n# RAG QA Node that checks if the question is movie-related\ndef rag_qa_node(state: ChatState) -> ChatState:\n    if not state.messages:\n        return state  # Return the state as is if no messages exist\n\n    # Extract the query (the last user message)\n    query = state.messages[-1][\"content\"]\n    \n    # Placeholder for the answer (get_answer function should be defined elsewhere)\n    answer = get_answer(query)\n    \n    # If no answer found or the answer is generic, fallback to default response\n    if not answer or \"no information\" in answer.lower():\n        answer = fallback()\n    \n    # Add the assistant's response to the message list\n    updated_messages = state.messages + [{\"role\": \"assistant\", \"content\": answer}]\n    return ChatState(messages=updated_messages)\n\n# Initialize LangGraph StateGraph with ChatState as the schema\ngraph = StateGraph(ChatState)\n\n# Add the rag_qa_node as a node in the graph\ngraph.add_node(\"RAG_QA\", rag_qa_node)\n\n# Set the entry point and finish point for the graph\ngraph.set_entry_point(\"RAG_QA\")\ngraph.set_finish_point(\"RAG_QA\")\n\n# Compile the app\napp = graph.compile()\n\n# Function to start the chat\ndef start_chat():\n    # Initialize the initial state with no messages\n    state = ChatState(messages=[])\n\n    print(\"ğŸ¬ MovieBot is ready! Ask me about any movie plot. Type 'exit' to quit.\")\n\n    while True:\n        # Get user input\n        user_input = input(\"You: \")\n        \n        if user_input.lower() in [\"exit\", \"quit\"]:\n            print(\"ğŸ‘‹ Bye!\")\n            break\n\n        # Update the state with the user's message\n        state_dict = {\"messages\": state.messages + [{\"role\": \"user\", \"content\": user_input}]}\n\n        # Invoke the graph with the updated state\n        result = app.invoke(state_dict)\n\n        # Print the assistant's response\n        print(\"Bot:\", result[\"messages\"][-1][\"content\"]) \n\n        # Update the state to include the new assistant's message\n        state = ChatState(messages=result[\"messages\"])\n\n\nif __name__ == \"__main__\":\n    start_chat()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T03:43:10.795990Z","iopub.execute_input":"2025-04-07T03:43:10.796328Z","iopub.status.idle":"2025-04-07T03:43:34.207334Z","shell.execute_reply.started":"2025-04-07T03:43:10.796301Z","shell.execute_reply":"2025-04-07T03:43:34.206253Z"}},"outputs":[{"name":"stdout","text":"ğŸ¬ MovieBot is ready! Ask me about any movie plot. Type 'exit' to quit.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You:  hi can u tell me about movie Bait?\n"},{"name":"stdout","text":"Bot: Certainly! The movie *Bait* is about a middle-aged man named Marko, played by Haas, who has been searching for a lost gold mine for nearly 20 years, and to share expenses for a prospecting expedition he teams up with a bright young man, Ray Brighton, played by Agar. After they find the mine, Marko decides he doesn't want to share with his partner and plans to murder him by spending the winter together in a shack far from civilization with Marko's trashy young wife, played by Moore, so he can catch them in adultery and use the \"unwritten law\" to kill Brighton and escape punishment, but the plot backfires.\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You:  quit\n"},{"name":"stdout","text":"ğŸ‘‹ Bye!\n","output_type":"stream"}],"execution_count":16}]}